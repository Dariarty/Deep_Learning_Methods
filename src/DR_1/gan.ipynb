{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb1644fd",
   "metadata": {},
   "source": [
    "### В данной работе разарбатываем модель генеративно-состязательной сети (GAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "708a3a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]\n",
      "Tensorflow 2.7.0\n",
      "Tensorflow uses GPU\n"
     ]
    }
   ],
   "source": [
    "#В данной работе использую Python 3.9.13 и tensorflow 2.7.0\n",
    "\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "\n",
    "# Вывод версий Python и Tensorflow\n",
    "print(\"Python\", sys.version)\n",
    "print(\"Tensorflow\", tf.__version__)\n",
    "\n",
    "# Убеждаюсь, что tensorflow использует GPU\n",
    "available_gpus = tf.config.list_physical_devices('GPU') # Динамическое использование памяти GPU\n",
    "if available_gpus:\n",
    "    try:\n",
    "        for gpu in available_gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"Tensorflow uses GPU\")\n",
    "    except RuntimeError as error:\n",
    "        print(\"GPU Error:\", error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6874fb",
   "metadata": {},
   "source": [
    "### Генератор\n",
    "Начинаем с модели generator, которая преобразует вектор (из скрытого пространства, полученного во время обучения, который будет выбираться случайно) в изображение-кандидат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e70c943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32)]              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32768)             1081344   \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 32768)             0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 16, 16, 256)       819456    \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 32, 32, 256)      1048832   \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 256)       1638656   \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 32, 32, 256)       1638656   \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 32, 32, 3)         37635     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,264,579\n",
      "Trainable params: 6,264,579\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "latent_dim = 32\n",
    "height = 32\n",
    "width = 32\n",
    "channels = 3\n",
    "generator_input = keras.Input(shape=(latent_dim,))\n",
    "x = keras.layers.Dense(128 * 16 * 16)(generator_input)\n",
    "x = keras.layers.LeakyReLU()(x)\n",
    "x = keras.layers.Reshape((16, 16, 128))(x)\n",
    "x = keras.layers.Conv2D(256, 5, padding='same')(x)\n",
    "x = keras.layers.LeakyReLU()(x)\n",
    "x = keras.layers.Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n",
    "x = keras.layers.LeakyReLU()(x)\n",
    "x = keras.layers.Conv2D(256, 5, padding='same')(x)\n",
    "x = keras.layers.LeakyReLU()(x)\n",
    "x = keras.layers.Conv2D(256, 5, padding='same')(x)\n",
    "x = keras.layers.LeakyReLU()(x)\n",
    "x = keras.layers.Conv2D(channels, 7, activation='tanh', padding='same')(x) \n",
    "generator = keras.models.Model(generator_input, x) \n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b57ec4",
   "metadata": {},
   "source": [
    "### Дискриминатор\n",
    "Модель discriminator принимает на входе изображение-кандидат (реальное или искусственное) и относит его к одному из двух классов: «подделка» или «настоящее, имеющееся в обучающем наборе»."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b77b9c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 30, 30, 128)       3584      \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 30, 30, 128)       0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 14, 14, 128)       262272    \n",
      "                                                                 \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 14, 14, 128)       0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 6, 6, 128)         262272    \n",
      "                                                                 \n",
      " leaky_re_lu_7 (LeakyReLU)   (None, 6, 6, 128)         0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 2, 2, 128)         262272    \n",
      "                                                                 \n",
      " leaky_re_lu_8 (LeakyReLU)   (None, 2, 2, 128)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 790,913\n",
      "Trainable params: 790,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator_input = keras.layers.Input(shape=(height, width, channels))\n",
    "x = keras.layers.Conv2D(128, 3)(discriminator_input)\n",
    "x = keras.layers.LeakyReLU()(x)\n",
    "x = keras.layers.Conv2D(128, 4, strides=2)(x)\n",
    "x = keras.layers.LeakyReLU()(x)\n",
    "x = keras.layers.Conv2D(128, 4, strides=2)(x)\n",
    "x = keras.layers.LeakyReLU()(x)\n",
    "x = keras.layers.Conv2D(128, 4, strides=2)(x)\n",
    "x = keras.layers.LeakyReLU()(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dropout(0.4)(x)\n",
    "x = keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "discriminator = keras.models.Model(discriminator_input, x)\n",
    "discriminator.summary()\n",
    "discriminator_optimizer = keras.optimizers.RMSprop(learning_rate=0.0008, clipvalue=1.0, decay=1e-8)\n",
    "discriminator.compile(optimizer=discriminator_optimizer,\n",
    "loss='binary_crossentropy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73fa4ef",
   "metadata": {},
   "source": [
    "### Состязательная сеть\n",
    "Состязательная сети объединяет генератор и дискриминатор.\n",
    "Обучение gan будет смещать веса в модели generator так, чтобы увеличить вероятность получить от дискриминатора ответ «настоящее», когда тот будет просматривать поддельное изображение. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cac9a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.trainable = False\n",
    "gan_input = keras.Input(shape=(latent_dim,))\n",
    "gan_output = discriminator(generator(gan_input))\n",
    "gan = keras.models.Model(gan_input, gan_output)\n",
    "gan_optimizer = keras.optimizers.RMSprop(learning_rate=0.0004, clipvalue=1.0, decay=1e-8)\n",
    "gan.compile(optimizer=gan_optimizer, loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2671e19c",
   "metadata": {},
   "source": [
    "### Обучение сети DCGAN\n",
    "Используются изображения собак. Настоящие и сгенерированные изображения сохраняются через каждые 100 итераций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0fea12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator loss: 0.6964086294174194\n",
      "adversarial loss: 0.7133448719978333\n",
      "discriminator loss: 0.7017762064933777\n",
      "adversarial loss: 0.7296949625015259\n",
      "discriminator loss: 0.6852512359619141\n",
      "adversarial loss: 0.7301290035247803\n",
      "discriminator loss: 0.6507151126861572\n",
      "adversarial loss: 1.0743067264556885\n",
      "discriminator loss: 0.7077747583389282\n",
      "adversarial loss: 0.7300721406936646\n",
      "discriminator loss: 0.6987818479537964\n",
      "adversarial loss: 0.7763774991035461\n",
      "discriminator loss: 0.7037621736526489\n",
      "adversarial loss: 0.7237204313278198\n",
      "discriminator loss: 0.6838155388832092\n",
      "adversarial loss: 0.7416655421257019\n",
      "discriminator loss: 0.6992554664611816\n",
      "adversarial loss: 0.7640292048454285\n",
      "discriminator loss: 0.696486234664917\n",
      "adversarial loss: 0.7364130020141602\n",
      "discriminator loss: 0.7181165218353271\n",
      "adversarial loss: 0.7533351182937622\n",
      "discriminator loss: 0.6884658932685852\n",
      "adversarial loss: 0.7467382550239563\n",
      "discriminator loss: 0.701903223991394\n",
      "adversarial loss: 0.7120739221572876\n",
      "discriminator loss: 0.6957404613494873\n",
      "adversarial loss: 0.7678910493850708\n",
      "discriminator loss: 0.7412554025650024\n",
      "adversarial loss: 0.7916300296783447\n",
      "discriminator loss: 0.6792682409286499\n",
      "adversarial loss: 0.7560203671455383\n",
      "discriminator loss: 0.6784394979476929\n",
      "adversarial loss: 0.8124676942825317\n",
      "discriminator loss: 0.6829910278320312\n",
      "adversarial loss: 0.7466522455215454\n",
      "discriminator loss: 0.6907942891120911\n",
      "adversarial loss: 0.7461572289466858\n",
      "discriminator loss: 0.7288728952407837\n",
      "adversarial loss: 0.7637835741043091\n",
      "discriminator loss: 0.6894121170043945\n",
      "adversarial loss: 0.7647077441215515\n",
      "discriminator loss: 0.694905698299408\n",
      "adversarial loss: 0.7546180486679077\n",
      "discriminator loss: 0.716350257396698\n",
      "adversarial loss: 0.7356095314025879\n",
      "discriminator loss: 0.6794642806053162\n",
      "adversarial loss: 0.7403144836425781\n",
      "discriminator loss: 0.6788243651390076\n",
      "adversarial loss: 0.7503186464309692\n",
      "discriminator loss: 0.7186681032180786\n",
      "adversarial loss: 0.8115978240966797\n",
      "discriminator loss: 0.7128398418426514\n",
      "adversarial loss: 0.7995395064353943\n",
      "discriminator loss: 0.6800550818443298\n",
      "adversarial loss: 0.7138704061508179\n",
      "discriminator loss: 0.6958199143409729\n",
      "adversarial loss: 0.717788577079773\n",
      "discriminator loss: 0.7008328437805176\n",
      "adversarial loss: 0.7354415655136108\n",
      "discriminator loss: 0.6805745363235474\n",
      "adversarial loss: 0.8731652498245239\n",
      "discriminator loss: 0.680896520614624\n",
      "adversarial loss: 0.7781159281730652\n",
      "discriminator loss: 0.6802952885627747\n",
      "adversarial loss: 0.7488018274307251\n",
      "discriminator loss: 0.6864088773727417\n",
      "adversarial loss: 0.7833432555198669\n",
      "discriminator loss: 0.7065278887748718\n",
      "adversarial loss: 0.7470952272415161\n",
      "discriminator loss: 0.6848751902580261\n",
      "adversarial loss: 0.857402503490448\n",
      "discriminator loss: 0.6866785287857056\n",
      "adversarial loss: 0.7701471447944641\n",
      "discriminator loss: 0.6940633058547974\n",
      "adversarial loss: 0.8036974668502808\n",
      "discriminator loss: 0.7056186199188232\n",
      "adversarial loss: 0.719814658164978\n",
      "discriminator loss: 0.6858839988708496\n",
      "adversarial loss: 0.7912286520004272\n",
      "discriminator loss: 0.6799910664558411\n",
      "adversarial loss: 2.728074312210083\n",
      "discriminator loss: 0.6726419925689697\n",
      "adversarial loss: 0.7824587821960449\n",
      "discriminator loss: 0.6987811326980591\n",
      "adversarial loss: 0.7358531951904297\n",
      "discriminator loss: 0.6996814012527466\n",
      "adversarial loss: 0.7756639719009399\n",
      "discriminator loss: 0.7152695655822754\n",
      "adversarial loss: 0.8873074650764465\n",
      "discriminator loss: 0.6785638928413391\n",
      "adversarial loss: 0.8898817300796509\n",
      "discriminator loss: 0.6954589486122131\n",
      "adversarial loss: 0.7989553213119507\n",
      "discriminator loss: 0.6791647672653198\n",
      "adversarial loss: 0.7371498942375183\n",
      "discriminator loss: 0.7229866981506348\n",
      "adversarial loss: 0.7188553214073181\n",
      "discriminator loss: 0.6846596598625183\n",
      "adversarial loss: 0.8251761198043823\n",
      "discriminator loss: 0.6729557514190674\n",
      "adversarial loss: 0.8676325678825378\n",
      "discriminator loss: 0.656342625617981\n",
      "adversarial loss: 0.7973008751869202\n",
      "discriminator loss: 0.6857420802116394\n",
      "adversarial loss: 0.7799729108810425\n",
      "discriminator loss: 0.7032288908958435\n",
      "adversarial loss: 0.7700628042221069\n",
      "discriminator loss: 0.6856447458267212\n",
      "adversarial loss: 0.8600957989692688\n",
      "discriminator loss: 0.7023059725761414\n",
      "adversarial loss: 0.8160440325737\n",
      "discriminator loss: 0.8960882425308228\n",
      "adversarial loss: 0.7949967980384827\n",
      "discriminator loss: 0.707806408405304\n",
      "adversarial loss: 0.7748064994812012\n",
      "discriminator loss: 0.7766562700271606\n",
      "adversarial loss: 1.100480079650879\n",
      "discriminator loss: 0.693787693977356\n",
      "adversarial loss: 0.8377801775932312\n",
      "discriminator loss: 0.6322999596595764\n",
      "adversarial loss: 0.8185601234436035\n",
      "discriminator loss: 0.7015476822853088\n",
      "adversarial loss: 0.7523806691169739\n",
      "discriminator loss: 0.7055405378341675\n",
      "adversarial loss: 0.8566105961799622\n",
      "discriminator loss: 0.6965142488479614\n",
      "adversarial loss: 0.8740803003311157\n",
      "discriminator loss: 0.68524569272995\n",
      "adversarial loss: 0.8344189524650574\n",
      "discriminator loss: 0.6878684163093567\n",
      "adversarial loss: 0.8255779147148132\n",
      "discriminator loss: 0.6922720074653625\n",
      "adversarial loss: 0.7454179525375366\n",
      "discriminator loss: 0.6861931085586548\n",
      "adversarial loss: 0.7174436450004578\n",
      "discriminator loss: 0.6881891489028931\n",
      "adversarial loss: 0.7501971125602722\n",
      "discriminator loss: 0.6955169439315796\n",
      "adversarial loss: 0.8664848208427429\n",
      "discriminator loss: 0.7606832981109619\n",
      "adversarial loss: 0.8980706930160522\n",
      "discriminator loss: 0.6942211389541626\n",
      "adversarial loss: 0.6717408895492554\n",
      "discriminator loss: 0.6985758543014526\n",
      "adversarial loss: 0.8238398432731628\n",
      "discriminator loss: 0.6981742978096008\n",
      "adversarial loss: 0.7540813684463501\n",
      "discriminator loss: 0.6978034973144531\n",
      "adversarial loss: 0.8196055293083191\n",
      "discriminator loss: 0.7031974792480469\n",
      "adversarial loss: 0.8210137486457825\n",
      "discriminator loss: 0.7050032615661621\n",
      "adversarial loss: 0.7748254537582397\n",
      "discriminator loss: 0.6780539155006409\n",
      "adversarial loss: 0.7569659948348999\n",
      "discriminator loss: 0.6891024708747864\n",
      "adversarial loss: 0.7642046809196472\n",
      "discriminator loss: 0.6873219609260559\n",
      "adversarial loss: 0.7212382555007935\n",
      "discriminator loss: 0.7145243287086487\n",
      "adversarial loss: 0.7468807101249695\n",
      "discriminator loss: 0.6917331218719482\n",
      "adversarial loss: 0.8296686410903931\n",
      "discriminator loss: 0.6794174909591675\n",
      "adversarial loss: 0.7418553233146667\n",
      "discriminator loss: 0.6823321580886841\n",
      "adversarial loss: 0.8440784215927124\n",
      "discriminator loss: 0.6933091878890991\n",
      "adversarial loss: 0.8178725242614746\n",
      "discriminator loss: 0.7171913981437683\n",
      "adversarial loss: 0.7925982475280762\n",
      "discriminator loss: 0.6999205350875854\n",
      "adversarial loss: 0.7574125528335571\n",
      "discriminator loss: 0.7255380749702454\n",
      "adversarial loss: 0.7762983441352844\n",
      "discriminator loss: 0.7065522074699402\n",
      "adversarial loss: 0.7531532645225525\n",
      "discriminator loss: 0.6766852140426636\n",
      "adversarial loss: 0.7809168100357056\n",
      "discriminator loss: 0.6965732574462891\n",
      "adversarial loss: 0.7952848672866821\n",
      "discriminator loss: 0.7200642824172974\n",
      "adversarial loss: 0.8299497365951538\n",
      "discriminator loss: 0.6871854662895203\n",
      "adversarial loss: 0.8709992170333862\n",
      "discriminator loss: 0.6939800977706909\n",
      "adversarial loss: 0.7509444355964661\n",
      "discriminator loss: 0.7255455255508423\n",
      "adversarial loss: 0.6742191314697266\n",
      "discriminator loss: 0.6867803335189819\n",
      "adversarial loss: 0.7224749326705933\n",
      "discriminator loss: 0.6881774067878723\n",
      "adversarial loss: 0.7825921773910522\n",
      "discriminator loss: 0.6886876225471497\n",
      "adversarial loss: 0.7815377712249756\n",
      "discriminator loss: 0.7112582921981812\n",
      "adversarial loss: 0.8494598269462585\n",
      "discriminator loss: 0.6987448334693909\n",
      "adversarial loss: 0.8329544067382812\n",
      "discriminator loss: 0.6970706582069397\n",
      "adversarial loss: 0.779714822769165\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "(x_train, y_train), (_, _) = keras.datasets.cifar10.load_data()\n",
    "x_train = x_train[y_train.flatten() == 5] # Изображения собак\n",
    "x_train = x_train.reshape((x_train.shape[0], height, width, channels)).astype('float32') / 255.\n",
    "\n",
    "iterations = 10000\n",
    "batch_size = 20\n",
    "save_dir = 'generated_images'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "start = 0\n",
    "\n",
    "for step in range(iterations + 1):\n",
    "    # Генерация случайного шума\n",
    "    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
    "\n",
    "    # Генерация изображений\n",
    "    generated_images = generator.predict(random_latent_vectors)\n",
    "\n",
    "    # Подготовка данных: настоящие + сгенерированные изображения\n",
    "    stop = start + batch_size\n",
    "    real_images = x_train[start: stop]\n",
    "    combined_images = np.concatenate([generated_images, real_images])\n",
    "\n",
    "    # Метки: 1 — подделка, 0 — настоящее\n",
    "    labels = np.concatenate([np.ones((batch_size, 1)), np.zeros((batch_size, 1))])\n",
    "    labels += 0.05 * np.random.random(labels.shape)  # шум на метках для устойчивости\n",
    "\n",
    "    # Обучение дискриминатора\n",
    "    d_loss = discriminator.train_on_batch(combined_images, labels)\n",
    "\n",
    "    # Новые случайные точки и обучение генератора через GAN\n",
    "    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
    "    misleading_targets = np.zeros((batch_size, 1))  # генератор хочет, чтобы дискриминатор сказал \"настоящее\"\n",
    "    a_loss = gan.train_on_batch(random_latent_vectors, misleading_targets)\n",
    "\n",
    "    start += batch_size\n",
    "    if start > len(x_train) - batch_size:\n",
    "        start = 0\n",
    "\n",
    "    # Каждые 100 итераций сохранение модели и изображений\n",
    "    if step % 100 == 0:\n",
    "        gan.save_weights('gan.h5')\n",
    "        print('discriminator loss:', d_loss)\n",
    "        print('adversarial loss:', a_loss)\n",
    "\n",
    "        # Сохраняем сгенерированное изображение\n",
    "        img = keras.preprocessing.image.array_to_img(generated_images[0] * 255., scale=False)\n",
    "        img.save(os.path.join(save_dir, f'generated_image_step_{step}.png'))\n",
    "\n",
    "        # Сохраняем настоящее изображение\n",
    "        img = keras.preprocessing.image.array_to_img(real_images[0] * 255., scale=False)\n",
    "        img.save(os.path.join(save_dir, f'real_image_step_{step}.png'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
