{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb1644fd",
   "metadata": {},
   "source": [
    "### В данной работе разарбатываем модель генеративно-состязательной сети (GAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "708a3a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]\n",
      "Tensorflow 2.7.0\n",
      "Tensorflow uses GPU\n"
     ]
    }
   ],
   "source": [
    "#В данной работе использую Python 3.9.13 и tensorflow 2.7.0\n",
    "\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "\n",
    "# Вывод версий Python и Tensorflow\n",
    "print(\"Python\", sys.version)\n",
    "print(\"Tensorflow\", tf.__version__)\n",
    "\n",
    "# Убеждаюсь, что tensorflow использует GPU\n",
    "available_gpus = tf.config.list_physical_devices('GPU') # Динамическое использование памяти GPU\n",
    "if available_gpus:\n",
    "    try:\n",
    "        for gpu in available_gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"Tensorflow uses GPU\")\n",
    "    except RuntimeError as error:\n",
    "        print(\"GPU Error:\", error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6874fb",
   "metadata": {},
   "source": [
    "### Генератор\n",
    "Начинаем с модели generator, которая преобразует вектор (из скрытого пространства, полученного во время обучения, который будет выбираться случайно) в изображение-кандидат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e70c943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32)]              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32768)             1081344   \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 32768)             0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 16, 16, 256)       819456    \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 32, 32, 256)      1048832   \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 256)       1638656   \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 32, 32, 256)       1638656   \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 32, 32, 3)         37635     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,264,579\n",
      "Trainable params: 6,264,579\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "latent_dim = 32\n",
    "height = 32\n",
    "width = 32\n",
    "channels = 3\n",
    "generator_input = keras.Input(shape=(latent_dim,))\n",
    "x = keras.layers.Dense(128 * 16 * 16)(generator_input)\n",
    "x = keras.layers.LeakyReLU()(x)\n",
    "x = keras.layers.Reshape((16, 16, 128))(x)\n",
    "x = keras.layers.Conv2D(256, 5, padding='same')(x)\n",
    "x = keras.layers.LeakyReLU()(x)\n",
    "x = keras.layers.Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n",
    "x = keras.layers.LeakyReLU()(x)\n",
    "x = keras.layers.Conv2D(256, 5, padding='same')(x)\n",
    "x = keras.layers.LeakyReLU()(x)\n",
    "x = keras.layers.Conv2D(256, 5, padding='same')(x)\n",
    "x = keras.layers.LeakyReLU()(x)\n",
    "x = keras.layers.Conv2D(channels, 7, activation='tanh', padding='same')(x) \n",
    "generator = keras.models.Model(generator_input, x) \n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b57ec4",
   "metadata": {},
   "source": [
    "### Дискриминатор\n",
    "Модель discriminator принимает на входе изображение-кандидат (реальное или искусственное) и относит его к одному из двух классов: «подделка» или «настоящее, имеющееся в обучающем наборе»."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b77b9c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 30, 30, 128)       3584      \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 30, 30, 128)       0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 14, 14, 128)       262272    \n",
      "                                                                 \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 14, 14, 128)       0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 6, 6, 128)         262272    \n",
      "                                                                 \n",
      " leaky_re_lu_7 (LeakyReLU)   (None, 6, 6, 128)         0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 2, 2, 128)         262272    \n",
      "                                                                 \n",
      " leaky_re_lu_8 (LeakyReLU)   (None, 2, 2, 128)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 790,913\n",
      "Trainable params: 790,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Work\\repo\\Deep_Learning_Methods\\.venv\\lib\\site-packages\\keras\\optimizer_v2\\rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(RMSprop, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "discriminator_input = keras.layers.Input(shape=(height, width, channels))\n",
    "x = keras.layers.Conv2D(128, 3)(discriminator_input)\n",
    "x = keras.layers.LeakyReLU()(x)\n",
    "x = keras.layers.Conv2D(128, 4, strides=2)(x)\n",
    "x = keras.layers.LeakyReLU()(x)\n",
    "x = keras.layers.Conv2D(128, 4, strides=2)(x)\n",
    "x = keras.layers.LeakyReLU()(x)\n",
    "x = keras.layers.Conv2D(128, 4, strides=2)(x)\n",
    "x = keras.layers.LeakyReLU()(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dropout(0.4)(x)\n",
    "x = keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "discriminator = keras.models.Model(discriminator_input, x)\n",
    "discriminator.summary()\n",
    "discriminator_optimizer = keras.optimizers.RMSprop(lr=0.0008, clipvalue=1.0, decay=1e-8)\n",
    "discriminator.compile(optimizer=discriminator_optimizer,\n",
    "loss='binary_crossentropy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73fa4ef",
   "metadata": {},
   "source": [
    "### Состязательная сеть\n",
    "Состязательная сети объединяет генератор и дискриминатор.\n",
    "Обучение gan будет смещать веса в модели generator так, чтобы увеличить вероятность получить от дискриминатора ответ «настоящее», когда тот будет просматривать поддельное изображение. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cac9a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.trainable = False\n",
    "gan_input = keras.Input(shape=(latent_dim,))\n",
    "gan_output = discriminator(generator(gan_input))\n",
    "gan = keras.models.Model(gan_input, gan_output)\n",
    "gan_optimizer = keras.optimizers.RMSprop(lr=0.0004, clipvalue=1.0, decay=1e-8)\n",
    "gan.compile(optimizer=gan_optimizer, loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2671e19c",
   "metadata": {},
   "source": [
    "### Обучение сети DCGAN\n",
    "Используются изображения собак. Настоящие и сгенерированные изображения сохраняются через каждые 100 итераций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fea12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator loss: 0.6886142492294312\n",
      "adversarial loss: 0.6793264150619507\n",
      "discriminator loss: 0.5416778326034546\n",
      "adversarial loss: 1.5965389013290405\n",
      "discriminator loss: 0.8156078457832336\n",
      "adversarial loss: 1.6827319860458374\n",
      "discriminator loss: 0.6826057434082031\n",
      "adversarial loss: 1.1224498748779297\n",
      "discriminator loss: 0.7052029371261597\n",
      "adversarial loss: 0.7782511711120605\n",
      "discriminator loss: 0.704055905342102\n",
      "adversarial loss: 0.7619809508323669\n",
      "discriminator loss: 0.6859291195869446\n",
      "adversarial loss: 0.7658388018608093\n",
      "discriminator loss: 0.7721633911132812\n",
      "adversarial loss: 0.7614760994911194\n",
      "discriminator loss: 0.6936203241348267\n",
      "adversarial loss: 0.7593921422958374\n",
      "discriminator loss: 0.6958518028259277\n",
      "adversarial loss: 0.723577618598938\n",
      "discriminator loss: 0.6930983662605286\n",
      "adversarial loss: 0.7477735280990601\n",
      "discriminator loss: 0.6917347311973572\n",
      "adversarial loss: 0.7305008769035339\n",
      "discriminator loss: 0.7174976468086243\n",
      "adversarial loss: 0.7456933259963989\n",
      "discriminator loss: 0.6951444745063782\n",
      "adversarial loss: 0.740135669708252\n",
      "discriminator loss: 0.6882427334785461\n",
      "adversarial loss: 0.7126795053482056\n",
      "discriminator loss: 0.6993557810783386\n",
      "adversarial loss: 0.7810169458389282\n",
      "discriminator loss: 0.7071426510810852\n",
      "adversarial loss: 0.7376192808151245\n",
      "discriminator loss: 0.7173125743865967\n",
      "adversarial loss: 1.4188547134399414\n",
      "discriminator loss: 0.6812960505485535\n",
      "adversarial loss: 0.7466815114021301\n",
      "discriminator loss: 0.700909435749054\n",
      "adversarial loss: 0.7401286959648132\n",
      "discriminator loss: 0.6964341998100281\n",
      "adversarial loss: 0.8338063955307007\n",
      "discriminator loss: 0.6849705576896667\n",
      "adversarial loss: 0.7641525864601135\n",
      "discriminator loss: 0.6947538256645203\n",
      "adversarial loss: 0.7200692892074585\n",
      "discriminator loss: 0.687861979007721\n",
      "adversarial loss: 0.9209068417549133\n",
      "discriminator loss: 0.6977485418319702\n",
      "adversarial loss: 0.7640336155891418\n",
      "discriminator loss: 0.6795360445976257\n",
      "adversarial loss: 0.9481413960456848\n",
      "discriminator loss: 0.6903548240661621\n",
      "adversarial loss: 0.7770024538040161\n",
      "discriminator loss: 0.6696422696113586\n",
      "adversarial loss: 0.6921676397323608\n",
      "discriminator loss: 0.6950124502182007\n",
      "adversarial loss: 0.7683762311935425\n",
      "discriminator loss: 0.7115756273269653\n",
      "adversarial loss: 0.9192317724227905\n",
      "discriminator loss: 0.7285875082015991\n",
      "adversarial loss: 0.7574571371078491\n",
      "discriminator loss: 0.6980822086334229\n",
      "adversarial loss: 0.7891272306442261\n",
      "discriminator loss: 0.6807413101196289\n",
      "adversarial loss: 0.8122544288635254\n",
      "discriminator loss: 0.6965559124946594\n",
      "adversarial loss: 0.7616430521011353\n",
      "discriminator loss: 0.7045994997024536\n",
      "adversarial loss: 0.9050464630126953\n",
      "discriminator loss: 0.6855795979499817\n",
      "adversarial loss: 0.7523521780967712\n",
      "discriminator loss: 0.6733326315879822\n",
      "adversarial loss: 0.7048357129096985\n",
      "discriminator loss: 0.6349236369132996\n",
      "adversarial loss: 0.8967132568359375\n",
      "discriminator loss: 0.6970983743667603\n",
      "adversarial loss: 0.994976818561554\n",
      "discriminator loss: 0.6623708009719849\n",
      "adversarial loss: 0.78863126039505\n",
      "discriminator loss: 0.6715400815010071\n",
      "adversarial loss: 0.7824887633323669\n",
      "discriminator loss: 0.6789768934249878\n",
      "adversarial loss: 0.9483339190483093\n",
      "discriminator loss: 0.6773425340652466\n",
      "adversarial loss: 0.7725216150283813\n",
      "discriminator loss: 0.716163158416748\n",
      "adversarial loss: 0.8308504223823547\n",
      "discriminator loss: 0.677939772605896\n",
      "adversarial loss: 0.7514883875846863\n",
      "discriminator loss: 0.6691864728927612\n",
      "adversarial loss: 0.9485863447189331\n",
      "discriminator loss: 0.692012369632721\n",
      "adversarial loss: 0.7737184762954712\n",
      "discriminator loss: 0.7058252096176147\n",
      "adversarial loss: 0.8448319435119629\n",
      "discriminator loss: 0.675744354724884\n",
      "adversarial loss: 0.7979071736335754\n",
      "discriminator loss: 0.6723066568374634\n",
      "adversarial loss: 0.8508827090263367\n",
      "discriminator loss: 0.657396137714386\n",
      "adversarial loss: 0.7958005666732788\n",
      "discriminator loss: 0.6246294975280762\n",
      "adversarial loss: 0.5874099135398865\n",
      "discriminator loss: 0.8303535580635071\n",
      "adversarial loss: 0.7192702293395996\n",
      "discriminator loss: 0.6898506879806519\n",
      "adversarial loss: 0.8279275894165039\n",
      "discriminator loss: 0.7004785537719727\n",
      "adversarial loss: 0.8073114156723022\n",
      "discriminator loss: 0.6672487854957581\n",
      "adversarial loss: 0.8824030160903931\n",
      "discriminator loss: 0.6812721490859985\n",
      "adversarial loss: 0.898074746131897\n",
      "discriminator loss: 0.6945817470550537\n",
      "adversarial loss: 0.9272502660751343\n",
      "discriminator loss: 0.671972393989563\n",
      "adversarial loss: 0.880311131477356\n",
      "discriminator loss: 0.7635124325752258\n",
      "adversarial loss: 0.6723617911338806\n",
      "discriminator loss: 0.6827806234359741\n",
      "adversarial loss: 0.7798946499824524\n",
      "discriminator loss: 0.6827742457389832\n",
      "adversarial loss: 0.767959713935852\n",
      "discriminator loss: 0.7401975393295288\n",
      "adversarial loss: 0.7317938208580017\n",
      "discriminator loss: 0.7285878658294678\n",
      "adversarial loss: 1.0219993591308594\n",
      "discriminator loss: 0.6983704566955566\n",
      "adversarial loss: 0.8544437289237976\n",
      "discriminator loss: 0.6357393264770508\n",
      "adversarial loss: 1.0451104640960693\n",
      "discriminator loss: 0.6935957074165344\n",
      "adversarial loss: 0.736979603767395\n",
      "discriminator loss: 0.6766555905342102\n",
      "adversarial loss: 0.7622633576393127\n",
      "discriminator loss: 0.6920340061187744\n",
      "adversarial loss: 0.9043219685554504\n",
      "discriminator loss: 0.7045246362686157\n",
      "adversarial loss: 0.6848554015159607\n",
      "discriminator loss: 0.6805136799812317\n",
      "adversarial loss: 0.956832766532898\n",
      "discriminator loss: 0.7064444422721863\n",
      "adversarial loss: 0.6766985654830933\n",
      "discriminator loss: 0.7009114027023315\n",
      "adversarial loss: 0.7705076336860657\n",
      "discriminator loss: 0.6697747111320496\n",
      "adversarial loss: 0.7591244578361511\n",
      "discriminator loss: 0.7014017701148987\n",
      "adversarial loss: 0.8087136149406433\n",
      "discriminator loss: 0.7155540585517883\n",
      "adversarial loss: 0.8707504272460938\n",
      "discriminator loss: 0.7047735452651978\n",
      "adversarial loss: 0.7408326268196106\n",
      "discriminator loss: 0.6942726969718933\n",
      "adversarial loss: 0.7817479372024536\n",
      "discriminator loss: 0.6784340143203735\n",
      "adversarial loss: 0.755105197429657\n",
      "discriminator loss: 0.6866018176078796\n",
      "adversarial loss: 0.7616628408432007\n",
      "discriminator loss: 0.7073944211006165\n",
      "adversarial loss: 0.7953265905380249\n",
      "discriminator loss: 0.6765491962432861\n",
      "adversarial loss: 0.7209464311599731\n",
      "discriminator loss: 0.6770492196083069\n",
      "adversarial loss: 0.7446149587631226\n",
      "discriminator loss: 0.682106614112854\n",
      "adversarial loss: 0.8113292455673218\n",
      "discriminator loss: 0.6835584044456482\n",
      "adversarial loss: 0.8027094602584839\n",
      "discriminator loss: 0.8937171101570129\n",
      "adversarial loss: 0.8826078176498413\n",
      "discriminator loss: 0.6735562086105347\n",
      "adversarial loss: 0.8645147085189819\n",
      "discriminator loss: 0.6942984461784363\n",
      "adversarial loss: 0.8118859529495239\n",
      "discriminator loss: 0.6827898025512695\n",
      "adversarial loss: 0.8226561546325684\n",
      "discriminator loss: 0.6991199254989624\n",
      "adversarial loss: 0.7061727643013\n",
      "discriminator loss: 0.6837837100028992\n",
      "adversarial loss: 0.8295003771781921\n",
      "discriminator loss: 0.6936911344528198\n",
      "adversarial loss: 0.8346327543258667\n",
      "discriminator loss: 0.6899250745773315\n",
      "adversarial loss: 0.7309983968734741\n",
      "discriminator loss: 0.698226273059845\n",
      "adversarial loss: 0.8020780682563782\n",
      "discriminator loss: 0.7043747305870056\n",
      "adversarial loss: 0.7988554239273071\n",
      "discriminator loss: 0.6930916905403137\n",
      "adversarial loss: 0.7725875377655029\n",
      "discriminator loss: 0.688160240650177\n",
      "adversarial loss: 0.7356061339378357\n",
      "discriminator loss: 0.6861426830291748\n",
      "adversarial loss: 0.7212978601455688\n",
      "discriminator loss: 0.7001854181289673\n",
      "adversarial loss: 0.7797404527664185\n",
      "discriminator loss: 0.6982983350753784\n",
      "adversarial loss: 0.7789856195449829\n",
      "discriminator loss: 0.6547523736953735\n",
      "adversarial loss: 0.5977984666824341\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "(x_train, y_train), (_, _) = keras.datasets.cifar10.load_data()\n",
    "x_train = x_train[y_train.flatten() == 5] # Изображения собак\n",
    "x_train = x_train.reshape((x_train.shape[0], height, width, channels)).astype('float32') / 255.\n",
    "\n",
    "iterations = 10000\n",
    "batch_size = 20\n",
    "save_dir = 'generated_images'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "start = 0\n",
    "\n",
    "for step in range(iterations + 1):\n",
    "    # Генерация случайного шума\n",
    "    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
    "\n",
    "    # Генерация изображений\n",
    "    generated_images = generator.predict(random_latent_vectors)\n",
    "\n",
    "    # Подготовка данных: настоящие + сгенерированные изображения\n",
    "    stop = start + batch_size\n",
    "    real_images = x_train[start: stop]\n",
    "    combined_images = np.concatenate([generated_images, real_images])\n",
    "\n",
    "    # Метки: 1 — подделка, 0 — настоящее\n",
    "    labels = np.concatenate([np.ones((batch_size, 1)), np.zeros((batch_size, 1))])\n",
    "    labels += 0.05 * np.random.random(labels.shape)  # шум на метках для устойчивости\n",
    "\n",
    "    # Обучение дискриминатора\n",
    "    d_loss = discriminator.train_on_batch(combined_images, labels)\n",
    "\n",
    "    # Новые случайные точки и обучение генератора через GAN\n",
    "    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
    "    misleading_targets = np.zeros((batch_size, 1))  # генератор хочет, чтобы дискриминатор сказал \"настоящее\"\n",
    "    a_loss = gan.train_on_batch(random_latent_vectors, misleading_targets)\n",
    "\n",
    "    start += batch_size\n",
    "    if start > len(x_train) - batch_size:\n",
    "        start = 0\n",
    "\n",
    "    # Каждые 100 итераций сохранение модели и изображений\n",
    "    if step % 100 == 0:\n",
    "        gan.save_weights('gan.h5')\n",
    "        print('discriminator loss:', d_loss)\n",
    "        print('adversarial loss:', a_loss)\n",
    "\n",
    "        # Сохраняем сгенерированное изображение\n",
    "        img = keras.preprocessing.image.array_to_img(generated_images[0] * 255., scale=False)\n",
    "        img.save(os.path.join(save_dir, f'generated_image_step_{step}.png'))\n",
    "\n",
    "        # Сохраняем настоящее изображение\n",
    "        img = keras.preprocessing.image.array_to_img(real_images[0] * 255., scale=False)\n",
    "        img.save(os.path.join(save_dir, f'real_image_step_{step}.png'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
